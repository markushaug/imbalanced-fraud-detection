{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n",
      "Imbalance ratio in training data: 4.13\n",
      "Imbalance ratio in validation data: 4.13\n",
      "Imbalance ratio in test data: 4.13\n",
      "\n",
      "Number of samples in training data: 248823\n",
      "Number of samples in validation data: 31103\n",
      "Number of samples in test data: 31103\n",
      "\n",
      "Number of samples in training data: 248823\n",
      "Number of samples in validation data: 31103\n",
      "Number of samples in test data: 31103\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# imoprt data science libraries\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import ML libraries\n",
    "import keras\n",
    "import model_utils as mutils\n",
    "from model_utils.evaluation import get_metrics, evaluate_model, table\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pyod\n",
    "# from pyod.models.mo_gaal import MO_GAAL\n",
    "\n",
    "current_k_fold=10\n",
    "SEED=current_k_fold**3\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# pandas options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# deserialize pre-processed data\n",
    "path_to_pickle = f'../data/kddcup/kdd_preprocessed_k{current_k_fold}.pkl'\n",
    "\n",
    "with open(path_to_pickle, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    X_train = data[\"X_train\"].to_numpy()\n",
    "    y_train = data[\"y_train\"].to_numpy()\n",
    "\n",
    "    X_val = data[\"X_val\"].to_numpy()\n",
    "    y_val = data[\"y_val\"].to_numpy()\n",
    "\n",
    "    X_test = data[\"X_test\"].to_numpy()\n",
    "    y_test = data[\"y_test\"].to_numpy()\n",
    "\n",
    "    col_names = data[\"col_names\"]\n",
    "\n",
    "print(\"Data loaded successfully\")\n",
    "\n",
    "# get imbalance ratio for each data set\n",
    "IR_train = mutils.imb_ratio(data[\"y_train\"].value_counts())\n",
    "IR_val = mutils.imb_ratio(data[\"y_val\"].value_counts())\n",
    "IR_test = mutils.imb_ratio(data[\"y_test\"].value_counts())\n",
    "\n",
    "# print imbalance ratios. They should be (nearly) the same. pct = 0.172 such as in the paper!\n",
    "print(f\"Imbalance ratio in training data: {IR_train}\")\n",
    "print(f\"Imbalance ratio in validation data: {IR_val}\")\n",
    "print(f\"Imbalance ratio in test data: {IR_test}\")\n",
    "\n",
    "# print number of samples in each data set\n",
    "print(f\"\\nNumber of samples in training data: {len(y_train)}\")\n",
    "print(f\"Number of samples in validation data: {len(y_val)}\")\n",
    "print(f\"Number of samples in test data: {len(y_test)}\")\n",
    "\n",
    "# Reshape\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "# print number of samples in each data set\n",
    "print(f\"\\nNumber of samples in training data: {len(y_train)}\")\n",
    "print(f\"Number of samples in validation data: {len(y_val)}\")\n",
    "print(f\"Number of samples in test data: {len(y_test)}\")\n",
    "\n",
    "# Normalize Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Multiple-Objective Generative Adversarial Active Learning.\n",
    "Part of the codes are adapted from\n",
    "https://github.com/leibinghe/GAAL-based-outlier-detection\n",
    "\"\"\"\n",
    "# Author: Winston Li <jk_zhengli@hotmail.com>\n",
    "# License: BSD 2 clause\n",
    "\n",
    "# Code slightly updated to run on Keras 3 by Markus Haug\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from pyod.models.base import BaseDetector\n",
    "from pyod.models.gaal_base import create_discriminator, create_generator\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "class MO_GAAL(BaseDetector):\n",
    "    \"\"\"Multi-Objective Generative Adversarial Active Learning.\n",
    "\n",
    "    MO_GAAL directly generates informative potential outliers to assist the\n",
    "    classifier in describing a boundary that can separate outliers from normal\n",
    "    data effectively. Moreover, to prevent the generator from falling into the\n",
    "    mode collapsing problem, the network structure of SO-GAAL is expanded from\n",
    "    a single generator (SO-GAAL) to multiple generators with different\n",
    "    objectives (MO-GAAL) to generate a reasonable reference distribution for\n",
    "    the whole dataset.\n",
    "    Read more in the :cite:`liu2019generative`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    contamination : float in (0., 0.5), optional (default=0.1)\n",
    "        The amount of contamination of the data set, i.e.\n",
    "        the proportion of outliers in the data set. Used when fitting to\n",
    "        define the threshold on the decision function.\n",
    "\n",
    "    k : int, optional (default=10)\n",
    "        The number of sub generators.\n",
    "\n",
    "    stop_epochs : int, optional (default=20)\n",
    "        The number of epochs of training. The number of total epochs equals to three times of stop_epochs.\n",
    "\n",
    "    lr_d : float, optional (default=0.01)\n",
    "        The learn rate of the discriminator.\n",
    "\n",
    "    lr_g : float, optional (default=0.0001)\n",
    "        The learn rate of the generator.\n",
    "\n",
    "\n",
    "    momentum : float, optional (default=0.9)\n",
    "        The momentum parameter for SGD.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    decision_scores_ : numpy array of shape (n_samples,)\n",
    "        The outlier scores of the training data.\n",
    "        The higher, the more abnormal. Outliers tend to have higher\n",
    "        scores. This value is available once the detector is fitted.\n",
    "\n",
    "    threshold_ : float\n",
    "        The threshold is based on ``contamination``. It is the\n",
    "        ``n_samples * contamination`` most abnormal samples in\n",
    "        ``decision_scores_``. The threshold is calculated for generating\n",
    "        binary outlier labels.\n",
    "\n",
    "    labels_ : int, either 0 or 1\n",
    "        The binary labels of the training data. 0 stands for inliers\n",
    "        and 1 for outliers/anomalies. It is generated by applying\n",
    "        ``threshold_`` on ``decision_scores_``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=10, stop_epochs=20, lr_d=0.01, lr_g=0.0001, momentum=0.9, contamination=0.1):\n",
    "        super(MO_GAAL, self).__init__(contamination=contamination)\n",
    "        self.k = k\n",
    "        self.stop_epochs = stop_epochs\n",
    "        self.lr_d = lr_d\n",
    "        self.lr_g = lr_g\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit detector. y is ignored in unsupervised methods.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "\n",
    "        y : Ignored\n",
    "            Not used, present for API consistency by convention.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Fitted estimator.\n",
    "        \"\"\"\n",
    "\n",
    "        X = check_array(X)\n",
    "        self._set_n_classes(y)\n",
    "        self.train_history = defaultdict(list)\n",
    "        names = locals()\n",
    "        epochs = self.stop_epochs * 3\n",
    "        stop = 0\n",
    "        latent_size = X.shape[1]\n",
    "        data_size = X.shape[0]\n",
    "        # Create discriminator\n",
    "        self.discriminator = create_discriminator(latent_size, data_size)\n",
    "        self.discriminator.compile(\n",
    "            optimizer=SGD(learning_rate=self.lr_d, momentum=self.momentum), loss='binary_crossentropy')\n",
    "\n",
    "        # Create k combine models\n",
    "        for i in range(self.k):\n",
    "            names['sub_generator' + str(i)] = create_generator(latent_size)\n",
    "            latent = Input(shape=(latent_size,))\n",
    "            names['fake' + str(i)] = names['sub_generator' + str(i)](latent)\n",
    "            self.discriminator.trainable = False\n",
    "            names['fake' + str(i)] = self.discriminator(names['fake' + str(i)])\n",
    "            names['combine_model' + str(i)] = Model(latent,\n",
    "                                                    names['fake' + str(i)])\n",
    "            names['combine_model' + str(i)].compile(\n",
    "                optimizer=SGD(learning_rate=self.lr_g,\n",
    "                              momentum=self.momentum),\n",
    "                loss='binary_crossentropy')\n",
    "\n",
    "        # Start iteration\n",
    "        for epoch in range(epochs):\n",
    "            print('Epoch {} of {}'.format(epoch + 1, epochs))\n",
    "            batch_size = min(500, data_size)\n",
    "            num_batches = int(data_size / batch_size)\n",
    "\n",
    "            for index in range(num_batches):\n",
    "                print('\\nTesting for epoch {} index {}:'.format(epoch + 1,\n",
    "                                                                index + 1))\n",
    "\n",
    "                # Generate noise\n",
    "                noise_size = batch_size\n",
    "                noise = np.random.uniform(0, 1, (int(noise_size), latent_size))\n",
    "\n",
    "                # Get training data\n",
    "                data_batch = X[index * batch_size: (index + 1) * batch_size]\n",
    "\n",
    "                # Generate potential outliers\n",
    "                block = ((1 + self.k) * self.k) // 2\n",
    "                for i in range(self.k):\n",
    "                    if i != (self.k - 1):\n",
    "                        noise_start = int(\n",
    "                            (((self.k + (self.k - i + 1)) * i) / 2) * (\n",
    "                                    noise_size // block))\n",
    "                        noise_end = int(\n",
    "                            (((self.k + (self.k - i)) * (i + 1)) / 2) * (\n",
    "                                    noise_size // block))\n",
    "                        names['noise' + str(i)] = noise[noise_start:noise_end]\n",
    "                        names['generated_data' + str(i)] = names[\n",
    "                            'sub_generator' + str(i)].predict(\n",
    "                            names['noise' + str(i)], verbose=0)\n",
    "                    else:\n",
    "                        noise_start = int(\n",
    "                            (((self.k + (self.k - i + 1)) * i) / 2) * (\n",
    "                                    noise_size // block))\n",
    "                        names['noise' + str(i)] = noise[noise_start:noise_size]\n",
    "                        names['generated_data' + str(i)] = names[\n",
    "                            'sub_generator' + str(i)].predict(\n",
    "                            names['noise' + str(i)], verbose=0)\n",
    "\n",
    "                # Concatenate real data to generated data\n",
    "                for i in range(self.k):\n",
    "                    if i == 0:\n",
    "                        x = np.concatenate(\n",
    "                            (data_batch, names['generated_data' + str(i)]))\n",
    "                    else:\n",
    "                        x = np.concatenate(\n",
    "                            (x, names['generated_data' + str(i)]))\n",
    "                y = np.array([1] * batch_size + [0] * int(noise_size))\n",
    "\n",
    "                # Train discriminator\n",
    "                discriminator_loss = self.discriminator.train_on_batch(x, y)\n",
    "                self.train_history['discriminator_loss'].append(\n",
    "                    discriminator_loss)\n",
    "\n",
    "                # Get the target value of sub-generator\n",
    "                pred_scores = self.discriminator.predict(X).ravel()\n",
    "\n",
    "                for i in range(self.k):\n",
    "                    names['T' + str(i)] = np.percentile(pred_scores,\n",
    "                                                        i / self.k * 100)\n",
    "                    names['trick' + str(i)] = np.array(\n",
    "                        [float(names['T' + str(i)])] * noise_size)\n",
    "\n",
    "                # Train generator\n",
    "                noise = np.random.uniform(0, 1, (int(noise_size), latent_size))\n",
    "                if stop == 0:\n",
    "                    for i in range(self.k):\n",
    "                        names['sub_generator' + str(i) + '_loss'] = \\\n",
    "                            names['combine_model' + str(i)].train_on_batch(\n",
    "                                noise, names['trick' + str(i)])\n",
    "                        self.train_history[\n",
    "                            'sub_generator{}_loss'.format(i)].append(\n",
    "                            names['sub_generator' + str(i) + '_loss'])\n",
    "                else:\n",
    "                    for i in range(self.k):\n",
    "                        names['sub_generator' + str(i) + '_loss'] = names[\n",
    "                            'combine_model' + str(i)].evaluate(noise, names[\n",
    "                            'trick' + str(i)])\n",
    "                        self.train_history[\n",
    "                            'sub_generator{}_loss'.format(i)].append(\n",
    "                            names['sub_generator' + str(i) + '_loss'])\n",
    "\n",
    "                generator_loss = 0\n",
    "                for i in range(self.k):\n",
    "                    # Access the last loss value which is the most recent one\n",
    "                    generator_loss += names['sub_generator' + str(i) + '_loss'][-1]\n",
    "\n",
    "                generator_loss = generator_loss / self.k\n",
    "                self.train_history['generator_loss'].append(generator_loss)\n",
    "\n",
    "                # Stop training generator\n",
    "                if epoch + 1 > self.stop_epochs:\n",
    "                    stop = 1\n",
    "\n",
    "        # Detection result\n",
    "        self.decision_scores_ = self.discriminator.predict(X).ravel()\n",
    "        self._process_decision_scores()\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Predict raw anomaly score of X using the fitted detector.\n",
    "\n",
    "        The anomaly score of an input sample is computed based on different\n",
    "        detector algorithms. For consistency, outliers are assigned with\n",
    "        larger anomaly scores.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape (n_samples, n_features)\n",
    "            The training input samples. Sparse matrices are accepted only\n",
    "            if they are supported by the base estimator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        anomaly_scores : numpy array of shape (n_samples,)\n",
    "            The anomaly score of the input samples.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, ['discriminator'])\n",
    "        X = check_array(X)\n",
    "        pred_scores = self.discriminator.predict(X).ravel()\n",
    "        return pred_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MO-GAAL hyperparameters from Hajek et al. 2023:\n",
    "\n",
    "contamination = len(y_train[y_train == 1]) / len(y_train) # proportion of frauds in the training dataset\n",
    "n_sub_generators = 5\n",
    "lr_discriminator = 0.01\n",
    "lr_generator = 0.0001\n",
    "epochs = 1\n",
    "\n",
    "mo_gaal = MO_GAAL(\n",
    "    k=n_sub_generators,\n",
    "    stop_epochs=epochs,\n",
    "    contamination=contamination,\n",
    "    lr_d=lr_discriminator,\n",
    "    lr_g=lr_generator,\n",
    ")\n",
    "\n",
    "# train in supervised manner\n",
    "clf = mo_gaal.fit(X_train, y_train) # 89 min with 1 epoch an n_sub_generators = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step\n"
     ]
    }
   ],
   "source": [
    "scores = mo_gaal.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6261/6261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 297us/step\n",
      "\u001b[1m1515/1515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step\n"
     ]
    }
   ],
   "source": [
    "scores_normal = df(mo_gaal.predict_proba(df(X_train)[y_train == 0])[:,1])\n",
    "scores_anomal = df(mo_gaal.predict_proba(df(X_train)[y_train == 1])[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df(scores).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Metric Score: 0.8301\n",
      "Best Threshold:  0.562\n"
     ]
    }
   ],
   "source": [
    "# let's find the best threshold\n",
    "\n",
    "best_metric = 0.\n",
    "best_th = 0.\n",
    "\n",
    "for threshold in np.arange(0.0, 1.0, 0.001):\n",
    "    current_metric = get_metrics(y_test, scores[:, 1], op=\">\", threshold=threshold)[\"F1\"]\n",
    "    if current_metric > best_metric:\n",
    "        best_metric = current_metric\n",
    "        best_th = threshold\n",
    "\n",
    "print(\"Best Metric Score:\", best_metric)\n",
    "print(\"Best Threshold: \", best_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tn': 23327.0,\n",
       " 'fp': 1716.0,\n",
       " 'fn': 543.0,\n",
       " 'tp': 5517.0,\n",
       " 'precision': 0.762754,\n",
       " 'recall': 0.91039604,\n",
       " 'AUCPRC': 0.7517,\n",
       " 'F1': 0.8301,\n",
       " 'ROCAUC': 0.911,\n",
       " 'MCC': 0.7893,\n",
       " 'ACC': 0.9274,\n",
       " 'GMEAN': 0.9209}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(y_test, scores[:, 1], threshold=0.562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saved_models/MOGAAL/mo_gaal_kdd.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(mo_gaal, './saved_models/MOGAAL/mo_gaal_kdd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = load('./saved_models/MOGAAL/mo_gaal_kdd.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
