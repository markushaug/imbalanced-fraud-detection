{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# local model helpers\n",
    "from model_utils import imb_ratio\n",
    "\n",
    "current_k_fold = 1\n",
    "\n",
    "# set seed\n",
    "SEED=current_k_fold**3\n",
    "\n",
    "# pandas options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Credit Card data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio in full data: 598.84\n",
      "Imbalance ratio in training data: 599.48\n",
      "Imbalance ratio in validation data: 602.68\n",
      "Imbalance ratio in test data: 590.1\n",
      "\n",
      "Number of samples in training data: 226980\n",
      "Number of samples in validation data: 28373\n",
      "Number of samples in test data: 28373\n",
      "\n",
      "Missing values in overall data: 0\n"
     ]
    }
   ],
   "source": [
    "# file paths\n",
    "full_data_path = \"./creditcard.csv\" # from Pozzolo et al. 2015, p. 7 \n",
    "\n",
    "# col names data set\n",
    "col_names = [\n",
    "    \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"label\"\n",
    "] # V1-V28 are PCA transformed features, but are anonymized due to confidentiality reasons and are not interpretable\n",
    "# Label is 1 if fraud, 0 otherwise\n",
    "\n",
    "# read full data set\n",
    "df = pd.read_csv(full_data_path, names=col_names, index_col=0, header=0)\n",
    "\n",
    "# drop duplicates  & time column\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.drop(\"Time\", axis=1, inplace=True)\n",
    "\n",
    "IR = imb_ratio(df.label.value_counts())\n",
    "print(f\"Imbalance ratio in full data: {IR}\")\n",
    "\n",
    "# Split data sets into X, y respectively\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "\"\"\"\n",
    "Partition Dataset:\n",
    "We stratify the split to ensure that the class distribution is preserved in the partitions.\n",
    "\"\"\"\n",
    "\n",
    "# First 80/20 split on original data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "# Then 50/50 split on test data for validation and test set.\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=SEED, stratify=y_test)\n",
    "\n",
    "# get imbalance ratio for each data set\n",
    "IR_train = imb_ratio(y_train.value_counts())\n",
    "IR_val = imb_ratio(y_val.value_counts())\n",
    "IR_test = imb_ratio(y_test.value_counts())\n",
    "\n",
    "# print imbalance ratios. They should be (nearly) the same.\n",
    "print(f\"Imbalance ratio in training data: {IR_train}\")\n",
    "print(f\"Imbalance ratio in validation data: {IR_val}\")\n",
    "print(f\"Imbalance ratio in test data: {IR_test}\")\n",
    "\n",
    "# print number of samples in each data set\n",
    "print(f\"\\nNumber of samples in training data: {len(y_train)}\")\n",
    "print(f\"Number of samples in validation data: {len(y_val)}\")\n",
    "print(f\"Number of samples in test data: {len(y_test)}\")\n",
    "\n",
    "# there are no missing values\n",
    "print(f\"\\nMissing values in overall data: {df.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export pre-processed data via serialization (pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data serialized to cc13_preprocessed_k1.pkl\n"
     ]
    }
   ],
   "source": [
    "# serialize data with pickle\n",
    "cc13_preprocessed = {\n",
    "    \"X\": X,\n",
    "    \"y\": y,\n",
    "    \"X_train\": X_train,\n",
    "    \"y_train\": y_train,\n",
    "    \n",
    "    \"X_val\": X_val,\n",
    "    \"y_val\": y_val,\n",
    "    \n",
    "    \"X_test\": X_test,\n",
    "    \"y_test\": y_test,\n",
    "      \n",
    "    \"col_names\": col_names,\n",
    "}\n",
    "\n",
    "with open(f'cc13_preprocessed_k{current_k_fold}.pkl', 'wb') as f:\n",
    "    pickle.dump(cc13_preprocessed, f)\n",
    "    print(f'Data serialized to cc13_preprocessed_k{current_k_fold}.pkl')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
